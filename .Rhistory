if (file.exists(recordsFileName)) { # load only retained occurrences
occs <- load(recordsFileName)
} else {
## standard cleaning procedures ##
# remove records without coordinates or dates,
# remove records from before 1900,
# date_collected column is recorded twice, remove one of them,
# remove imprecise coordinates
# load all (raw) occurrences
# occsRaw #
load(paste0('./species_records/00_',
gsub(' ', '_', tolower(sp)),
'_bien_all_occurrences.rda'))
# remove records without coordinates or dates to ensure geographic reliability
occs <- occsRaw[!(is.na(occsRaw$longitude)
| is.na(occsRaw$latitude)
| is.na(occsRaw$date_collected)), ]
# remove records before 1900
occs$year <- substr(occs$date_collected, 1, 4)
occs <- occs[occs$year >= 1900, ]
# remove records outside of study region countries
occs <- occs[(occs$country == 'United States'
| occs$country == 'Canada'
| occs$country == 'Mexico' ),]
# if date_collected column is duplicated, remove one of them
occs <- occs[!duplicated(as.list(occs))]
# remove imprecise coordinates
llOcc <- cbind(occs$longitude, occs$latitude)
coordPrecis <- coordPrecision(llOcc) # treat lat/long as decimal degrees
coordPrecisDMS <- coordPrecision(llOcc, dms = TRUE) # treat lat/long as DMS
precision <- data.frame(llOcc, coordPrecis, coordPrecisDMS)
# visualize the distribution of precision among occurrences
par(mfrow=c(2,1))
hist(precision$coordPrecis,
breaks = 100,
xlab='Coordinate uncertainty (m)',
ylab='Number of records',
main='decimal degrees',
col='red')
hist(precision$coordPrecisDMS,
breaks=100,
xlab='Coordinate uncertainty (m)',
ylab='Number of records',
main='dms',
col='red' )
# find the max between two precision measurements (dms vs decimal degrees)...
occs$precision <- pmax(coordPrecis, coordPrecisDMS)
# how many are deemed "imprecise"?
cat(paste0("Number of occurrences with precision > 1,000 m = ",
length(which(occs$precision > 1000)), '\n'))
# ...and remove occurrences where precision > 1,000 m
occs <- occs[which(occs$precision <= 1000), ]
## visualize occurrences in each stage ##
# convert to spatial object
occsSp <- SpatialPointsDataFrame(occs[, ll], data = occs, proj4string = CRS(wgs84_crs))
# plot cleaned occurrences
par(mfrow = c(1,1))
plot(range, col = scales::alpha('blue', 0.4), border = 'blue',
main = paste0("retained BIEN records w/ Little range map\n", sp))
plot(occsSp, pch = 16, cex = 0.3, col = 'red', add = TRUE)
map("state", add = TRUE)
map("world", add = TRUE)
# save retained records
save(occs, file = recordsFileName)
}
## thin data ##
thinnedFileName <- paste0('./species_records/02_',
gsub(' ', '_', tolower(sp)),
'_thinned_records.rData')
if (file.exists(thinnedFileName)) { # if already thinned, load that file
load(thinnedFileName)
} else { # otherwise, thin the occurrences!
# eliminate duplicates within each cell,
# using Lorenz environmental raster for reference
thinned <- elimCellDups(occs, lorenzRast, longLat = ll)
save(thinned, file = thinnedFileName)
}
# create sf objects for visualization
speciesSf_thinned <- st_as_sf(x = thinned,
coords = c(x = 'longitude',
y = 'latitude'),
crs = wgs84_crs)
speciesSf_occs <- st_as_sf(x = occs,
coords = c(x = 'longitude',
y = 'latitude'),
crs = wgs84_crs)
# load country/world basemap data for sf plotting
world <- ne_countries(returnclass = 'sf')
states <- ne_states(country = 'united states of america', returnclass = 'sf')
canada <- ne_states(country = 'canada', returnclass = 'sf')
ggplot(data = world) +
theme_bw() +
geom_sf(fill = "white") +
geom_sf(data = states, fill = NA) +
geom_sf(data = canada, fill = NA) +
geom_sf(data = speciesSf_thinned, col = scales::alpha('red'), cex = 0.5) +
coord_sf(xlim = c(min(occs$longitude), max(occs$longitude)),
ylim = c(min(occs$latitude), max(occs$latitude)), expand = TRUE) +
xlab("Longitude") +
ylab("Latitude") +
ggtitle(paste0(sp, ' occurences'), subtitle = "(Cleaned and cell duplicates eliminated)") +
theme(panel.grid.major = element_line(color = gray(0.5), linetype = "dashed",
size = 0.5), panel.background = element_rect(fill = "lavender"))
# create a buffer surrounding the Little range map to exclude occurrence data that
# is unrealistically out of range
bufferFileName <- paste0('./species_records/buffer/',
gsub(' ', '_', tolower(sp)),
'_buffer.rData')
if(!file.exists(bufferFileName)) { # if buffer hasn't been calculated, calculate it
# create a buffer that will include 97% (0.03 * # of occurrences) of the occurrences
# this threshold value can change based on how much you want to filter "out of bounds" data
threshold <- ceiling(0.03 * nrow(speciesSf_thinned))
# convert maps to albers NA for buffer calculation
rangeMapAlb <- st_transform(st_as_sf(x = range), getCRS('albersNA'))
speciesSf_thinnedAlb <- st_transform(speciesSf_thinned, getCRS('albersNA'))
speciesSf_occsAlb <- st_transform(speciesSf_occs, getCRS('albersNA'))
t <- 10 # start buffer distance at 10 km
# calculate buffer
calculate_buffer(t)
}
load(bufferFileName) # load in buffer
#  final dataset with occurrences outside buffer removed
speciesSf_final <- speciesSf_thinned %>%
mutate(within_range = lengths(st_within(x = speciesSf_thinnedAlb,
y = rangeMapAlb)),
within_buffer = lengths(st_within(x = speciesSf_thinnedAlb,
y = range_buffer))) %>%
filter(within_buffer > 0)
# buffers create circles around the edges of the range map
# since the range map isn't one succinct polygon, there are serveral overlapping circles
# so we need to unionize them to create one all-encompassing buffer
range_buffer_final <- st_union(range_buffer)
finalRecordsFileName <- paste0('./species_records/03_',
gsub(' ', '_', tolower(sp)),
'_final_records.rData')
save(speciesSf_final, range_buffer_final, file = finalRecordsFileName)
## visualize data after buffering ##
# cleaned & thinned occurrences with calculated buffer
# occurrences that fall outside the range are colored red
ggplot(data = world) +
theme_bw() +
geom_sf(fill = "white") +
geom_sf(data = states, fill = NA) +
geom_sf(data = canada, fill = NA) +
geom_sf(data = rangeMapAlb,
color = 'darkgreen',
fill = 'green',
alpha = 0.4,
inherit.aes = FALSE) +
geom_sf(data = range_buffer_final,
color = 'yellow',
fill = NA,
inherit.aes = FALSE) +
geom_sf(data = speciesSf_thinned_buffered,
size = 0.75,
aes(color = within_buffer > 0),
inherit.aes = FALSE) +
scale_colour_manual(values = setNames(c('black','red'),
c(T, F)),
guide = "none") +
guides(fill = "none") +
coord_sf(xlim = c(min(thinned$longitude) - 5,
max(thinned$longitude) + 5),
ylim = c(min(thinned$latitude),
max(thinned$latitude) + 5),
expand = TRUE) +
xlab("Longitude") +
ylab("Latitude") +
ggtitle(paste0(sp, ' occurences'),
subtitle = paste0("(Cleaned & thinned, buffer = ",
buffer_distance,
" km)")) +
theme(panel.grid.major = element_line(color = gray(0.5),
linetype = "dashed",
size = 0.5),
panel.background = element_rect(fill = "lavender"),
plot.title = element_text(hjust = 0.5),
plot.subtitle = element_text(hjust = 0.5))
# cleaned & thinned occurrences with calculated buffer
# records that fell outside buffer are removed
# red points are occurrences that fall outside of the Little range map
ggplot(data = world) +
theme_bw() +
geom_sf(fill = "white") +
geom_sf(data = states, fill = NA) +
geom_sf(data = canada, fill = NA) +
geom_sf(data = rangeMapAlb,
color = 'darkgreen',
fill = 'green',
alpha = 0.4,
inherit.aes = FALSE) +
geom_sf(data = range_buffer_final,
color = 'yellow',
fill = NA,
inherit.aes = FALSE) +
geom_sf(data = speciesSf_final,
size = 0.5,
aes(color = within_range > 0),
inherit.aes = FALSE) +
scale_colour_manual(values = setNames(c('black','red'),
c(T, F)),
guide = "none") +
guides(fill = "none") +
coord_sf(xlim = c(min(thinned$longitude) - 5,
max(thinned$longitude) + 5),
ylim = c(min(thinned$latitude),
max(thinned$latitude) + 5),
expand = TRUE) +
xlab("Longitude") +
ylab("Latitude") +
ggtitle(paste0(sp, ' occurences'),
subtitle = paste0("(Cleaned, thinned, and duplicates eliminated, with buffer = ",
buffer_distance,
" km)")) +
theme(panel.grid.major = element_line(color = gray(0.5),
linetype = "dashed",
size = 0.5),
panel.background = element_rect(fill = "lavender"),
plot.title = element_text(hjust = 0.5),
plot.subtitle = element_text(hjust = 0.5))
# How many occurrences are in the final dataset?
cat(paste0('Final number of occurrences = ', nrow(speciesSf_final), '\n'))
#   How many occurrences fell outside of the buffer?
cat(paste0("Number of occurrences outside buffer & excluded = ",
length(which(speciesSf_thinned_buffered$within_buffer == 0)), '\n'))
}
## start modeling ##
for (gcm in gcmList) {
gcm <- gsub('\'', '', gcm)
cat(paste0('\nGCM = ', gcm, ', Species: ', sp, '\n'))
# identify study region
studyRegionFileName <- paste0('./pollen/predictions-',
toupper(genus), '_meanpred_iceMask.tif')
studyRegionRasts <- brick(studyRegionFileName)
names(studyRegionRasts) <- c(paste0(tools::toTitleCase(genus),
"_pollen_predictions_", 0:21, "kybp"))
envData <- getClimRasts(pc, climYear) # retrieve clipped env data for given climate year
recordsFileName <- paste0('./species_records/03_',
gsub(' ', '_', tolower(sp)),
'_final_records.rData')
load(recordsFileName) # load records for given species
## prepare occurrence data for maxent ##
records <- data.frame(speciesSf_final)
records$geometry <- gsub("[c()]", "", records$geometry) # clean ll format in geometry column
# create separate columns for lat & long
records <- separate(data = records,
col = 'geometry',
into = ll,
sep = "\\,")
records$longitude <- as.double(records$longitude)
records$latitude <- as.double(records$latitude)
# extract environmental data at each occurrence point
occsEnv <- raster::extract(envData,
cbind(records$longitude,
records$latitude))
occsEnvDf <- as.data.frame(occsEnv) # convert to dataframe
records <- cbind(records, occsEnvDf) # add to records dataframe
## remove any records that fall in the water ##
if (exists('water')) rm(water) # remove 'water' from previous species
if (any(is.na(rowSums(occsEnvDf)))) { # define points in the water
water <- records[which(is.na(rowSums(occsEnvDf))), ]
water <- SpatialPointsDataFrame(water[,ll], data = water,
proj4 = getCRS('wgs84', TRUE))
}
if (any(is.na(rowSums(occsEnvDf)))) records <- records[-which(is.na(rowSums(occsEnvDf))), ] # remove records in water
print('line 615')
# convert to sp object for visualization
recordsSp <- SpatialPointsDataFrame(records[, ll], data = records,
proj4 = getCRS('wgs84', TRUE))
print('line 619')
# visualize points that fall in the water (colored in blue)
plot(recordsSp, pch = 16, cex = 0.5, col = "red",
main = paste0(sp, ' occurrences (BIEN) thinned'))
if (exists("water")) {
plot(water, col = 'blue', add = TRUE)
}
map("state", add = TRUE)
map("world", add = TRUE)
# save.image(paste0('./workspaces/04 - Modeling Workspace - Clipping ',
#                   sp, '_PC_', pc, '_GCM_', gcm))
bufferFileName <- paste0('./species_records/buffer/',
gsub(' ', '_', tolower(sp)),
'_buffer.rData')
load(bufferFileName)
## calculate calibration region at 320-km to extract bg sites from ##
# draw from all of NA #
calibBuffer <- st_buffer(st_transform(st_as_sf(x = recordsSp), getCRS('albersNA')),
dist = as_units(320, 'km'))
calibBuffer <- st_union(calibBuffer) # unionize
# convert to different crs objects
calibRegionSpAlb <- sp::spTransform(as(calibBuffer, 'Spatial'), getCRS('albersNA', TRUE))
calibRegionSpWgs <- sp::spTransform(calibRegionSpAlb, getCRS('wgs84', TRUE))
# set constants for retrieving background sites #
bgFileName <- paste0(baseFolder,
'background_sites/Random Background Sites across Study Region.Rdata')
# load bg sites in calibration region if they have already been defined (bgTestSp, bgCalib, bgEnv, bg)
# otherwise, define bg points
if(!file.exists(bgFileName)) getBG(bgFileName, calibRegionSpAlb)
load(bgFileName)
print('line 656')
# plot the bg sites to verify
plot(bgTestSp, pch = 16, cex = 0.5, col = "red",
main = paste0(sp, ' background sites'))
plot(calibRegionSpWgs, add = TRUE, border = 'blue')
map("state", add = TRUE)
map("world", add = TRUE)
climate <- envData
bgEnv <- raster::extract(climate, bgCalib) # extract environment at random background sites
bgEnv <- as.data.frame(bgEnv) # convert to dataframe
# remove any sites with NA for at least one variable #
isNa <- is.na(rowSums(bgEnv))
if (any(isNa)) {
bgCalib <- bgCalib[-which(isNa), ]
bgEnv <- bgEnv[-which(isNa), ]
}
bg <- cbind(bgCalib, bgEnv) # combine with coordinates
names(bg)[1:2] <- ll # rename lat/long columns, respectively
presBg <- c(rep(1, nrow(records)), rep(0, nrow(bg))) # identify presences
occsEnv <- occsEnv[complete.cases(occsEnv), ] # remove NA values
## prepare env data frame for maxent ##
env <- rbind(occsEnv, bgEnv)
env <- cbind(presBg, env)
env <- as.data.frame(env)
env <- env[complete.cases(env), ] # remove NA values
## run maxent for species ##
# model tuning for easy fine-tuning later
envModel_tune <- enmSdm::trainMaxNet(data = env, resp = 'presBg',
classes = 'lpq', out = c('models', 'tuning'))
envModel <- envModel_tune$models[[1]] # select best fitted model
predictors <- c(paste0('pca', 1:pc))
if(!dir.exists(paste0('./models/predictions/', speciesAb_))) dir.create(paste0('./models/predictions/', speciesAb_))
# prediction for given year
envMap <- predict(
climate[[predictors]],
envModel,
filename = paste0('./models/predictions/', speciesAb_, '/GCM_', gcm,
'_PC', pc, '_', climYear, 'ybp'),
clamp = F,
format='GTiff',
overwrite = T,
type='cloglog')
# remove XML file if it's created
file.remove(list.files(path = paste0('./models/predictions/', speciesAb_, '/'),
pattern = '.xml',
full.names = T))
envMapSp <- rasterToPolygons(envMap) # convert to spatial object for plotting
plot(range, border = 'blue', main = paste0('Maxent output, ', sp))
plot(envMap, add = TRUE)
plot(range, border = 'blue', add = TRUE)
map("state", add = TRUE)
map("world", add = TRUE)
points(records$longitude, records$latitude, pch = 16, cex = 0.6, col = 'red')
plot(envMap, main = paste0('Maxent output, ',
sp,
' occurrences'))
plot(range, border = 'blue', add = TRUE)
modelFileName <- paste0('./models/', speciesAb_, '_Maxent_PC',
pc, '_GCM_', gcm, '.rData')
save(envModel, file = modelFileName, compress = T, overwrite = T) # save model
outputFileName <- paste0('./models/predictions/', speciesAb_,
'/GCM_', gcm, '_PC', pc, '.rData')
save(bg, range, envMap, envModel, records, file = outputFileName, overwrite = T)
# put study regions in reverse order (from 21 KYBP to 0 KYBP)
studyRegionRasts <- unstack(studyRegionRasts)
studyRegionRasts <- stack(rev(studyRegionRasts))
if(!dir.exists('./predictions')) dir.create('./predictions') # create directory to store predictions
if(exists('preds')) rm(preds)
preds <- getPredictions(speciesAb_, pc)
preds <- projectRaster(preds, studyRegionRasts) # project predictions to study region
## mask by study region and force values to be within [0, 1] ##
# because the rasters can get pushed outside this during re-projection #
preds <- raster::calc(preds, fun = function(x) ifelse(x < 0, 0, x))
preds <- raster::calc(preds, fun = function(x) ifelse(x > 1, 1, x))
for (i in 1:nlayers(preds)) {
landMask <- (1 - studyRegionRasts[[i]])
preds[[i]] <- preds[[i]] * landMask
}
# names(preds) <- paste0('ybp', seq(21000, 0, by=-1000)) # rename rasters to respective year
if(!dir.exists(paste0('./predictions/', gcm))) dir.create(paste0('./predictions/', gcm))
writeRaster(stack(preds), paste0('./predictions/', gcm, '/', speciesAb_, '_GCM_', gcm, '_PC', pc),
format = 'GTiff', overwrite = T)
file.remove(list.files(path = paste0('./predictions/', gcm),
pattern = '.xml',
full.names = T))
save.image(paste0('./workspaces/06 - predictions (', gcm, ')'))
}
}
sink()
evalTypes <- c('geo', 'random')
## genus constants ##
genus <- 'fagus'
## genus constants ##
genus <- 'fraxinus'
speciesList <- paste0('Fraxinus ',
c('americana', 'caroliniana','cuspidata',
'greggii', 'nigra', 'pennsylvanica',
'profunda', 'quadrangulata'))
gcmList <- c('hadley', 'ccsm', 'ecbilt') # general circulation models for env data
baseFolder <- '/Volumes/lj_mac_22/MOBOT/by_genus/'
setwd(paste0(baseFolder, genus))
for (evalType in evalTypes) {
for (gcm in gcmList) {
print(paste0("GCM = ", gcm))
a <- data.frame(c(seq(1:5)))
c <- data.frame(c(seq(1:5)))
colnames(a)[1] <- colnames(c)[1] <- 'fold #'
for (sp in speciesList) {
speciesAb_ <- sub("(.{4})(.*)", "\\1_\\2",
paste0(substr(sp,1,4), toupper(substr(sub("^\\S+\\s+", '', sp),1,1)),
substr(sub("^\\S+\\s+", '', sp),2,4)))
evalFolderName <- paste0(baseFolder, genus, '/models/model_evaluations/',
speciesAb_, '/', evalType, '_k_folds/', gcm, '/')
# variable to store auc & cbi output
auc <- cbi <- rep(NA, 5)
for (m in 1:5) {
evalFileName <- paste0(evalFolderName, 'model_', m, '.Rdata')
load(evalFileName)
# evaluate
thisEval <- evaluate(p = as.vector(predPres), a = as.vector(predBg))
thisAuc <- thisEval@auc
thisCbi <- contBoyce(pres = predPres, bg = predBg)
# print(paste('AUC = ', round(thisAuc, 2), ' | CBI = ', round(thisCbi, 2)))
auc[m] <- thisAuc
cbi[m] <- thisCbi
}
a <- cbind(a, auc)
c <- cbind(c, cbi)
n <- ncol(a)
colnames(a)[n] <- colnames(c)[n] <- sp
}
write.xlsx(a, file = paste0('./models/model_evaluations/', evalType, '_evals.xlsx'),
sheetName = paste0(gcm, '_auc'), append = T, row.names = F)
write.xlsx(c, file = paste0('./models/model_evaluations/', evalType, '_evals.xlsx'),
sheetName = paste0(gcm, '_cbi'), append = T, row.names = F)
save(a, c, file = paste0('./models/model_evaluations/', gcm, '_evals.Rdata'))
}
}
for (evalType in evalTypes) {
for (gcm in gcmList) {
print(paste0("GCM = ", gcm))
a <- data.frame(c(seq(1:5)))
c <- data.frame(c(seq(1:5)))
colnames(a)[1] <- colnames(c)[1] <- 'fold #'
for (sp in speciesList) {
speciesAb_ <- sub("(.{4})(.*)", "\\1_\\2",
paste0(substr(sp,1,4), toupper(substr(sub("^\\S+\\s+", '', sp),1,1)),
substr(sub("^\\S+\\s+", '', sp),2,4)))
evalFolderName <- paste0(baseFolder, genus, '/models/model_evaluations/',
evalType, '_k_folds/', speciesAb_, '/', gcm, '/')
# variable to store auc & cbi output
auc <- cbi <- rep(NA, 5)
for (m in 1:5) {
evalFileName <- paste0(evalFolderName, 'model_', m, '.Rdata')
load(evalFileName)
# evaluate
thisEval <- evaluate(p = as.vector(predPres), a = as.vector(predBg))
thisAuc <- thisEval@auc
thisCbi <- contBoyce(pres = predPres, bg = predBg)
# print(paste('AUC = ', round(thisAuc, 2), ' | CBI = ', round(thisCbi, 2)))
auc[m] <- thisAuc
cbi[m] <- thisCbi
}
a <- cbind(a, auc)
c <- cbind(c, cbi)
n <- ncol(a)
colnames(a)[n] <- colnames(c)[n] <- sp
}
write.xlsx(a, file = paste0('./models/model_evaluations/', evalType, '_evals.xlsx'),
sheetName = paste0(gcm, '_auc'), append = T, row.names = F)
write.xlsx(c, file = paste0('./models/model_evaluations/', evalType, '_evals.xlsx'),
sheetName = paste0(gcm, '_cbi'), append = T, row.names = F)
save(a, c, file = paste0('./models/model_evaluations/', gcm, '_evals.Rdata'))
}
}
library(xlsx)
for (evalType in evalTypes) {
for (gcm in gcmList) {
print(paste0("GCM = ", gcm))
a <- data.frame(c(seq(1:5)))
c <- data.frame(c(seq(1:5)))
colnames(a)[1] <- colnames(c)[1] <- 'fold #'
for (sp in speciesList) {
speciesAb_ <- sub("(.{4})(.*)", "\\1_\\2",
paste0(substr(sp,1,4), toupper(substr(sub("^\\S+\\s+", '', sp),1,1)),
substr(sub("^\\S+\\s+", '', sp),2,4)))
evalFolderName <- paste0(baseFolder, genus, '/models/model_evaluations/',
evalType, '_k_folds/', speciesAb_, '/', gcm, '/')
# variable to store auc & cbi output
auc <- cbi <- rep(NA, 5)
for (m in 1:5) {
evalFileName <- paste0(evalFolderName, 'model_', m, '.Rdata')
load(evalFileName)
# evaluate
thisEval <- evaluate(p = as.vector(predPres), a = as.vector(predBg))
thisAuc <- thisEval@auc
thisCbi <- contBoyce(pres = predPres, bg = predBg)
# print(paste('AUC = ', round(thisAuc, 2), ' | CBI = ', round(thisCbi, 2)))
auc[m] <- thisAuc
cbi[m] <- thisCbi
}
a <- cbind(a, auc)
c <- cbind(c, cbi)
n <- ncol(a)
colnames(a)[n] <- colnames(c)[n] <- sp
}
write.xlsx(a, file = paste0('./models/model_evaluations/', evalType, '_evals.xlsx'),
sheetName = paste0(gcm, '_auc'), append = T, row.names = F)
write.xlsx(c, file = paste0('./models/model_evaluations/', evalType, '_evals.xlsx'),
sheetName = paste0(gcm, '_cbi'), append = T, row.names = F)
save(a, c, file = paste0('./models/model_evaluations/', gcm, '_evals.Rdata'))
}
}
